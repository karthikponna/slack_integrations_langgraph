{
    "id": "cedfe5bbd9cedafbfc2eebfbd867ca01",
    "metadata": {
        "id": "cedfe5bbd9cedafbfc2eebfbd867ca01",
        "url": "https://docs.zenml.io/concepts/snapshots",
        "title": "Pipeline Snapshots | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Create and run pipeline snapshots.",
            "keywords": null,
            "author": null,
            "og:title": "Pipeline Snapshots | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Create and run pipeline snapshots.",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/v68LQxO4ukWHKy6IqHWP",
            "twitter:card": "summary_large_image",
            "twitter:title": "Pipeline Snapshots | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Create and run pipeline snapshots.",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/v68LQxO4ukWHKy6IqHWP"
        }
    },
    "content": "`Ctrl``k`\nGitBook AssistantAsk\nProductResourcesGitHubStart free\nMore\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\nGitBook Assistant\nGitBook Assistant\nWorking...Thinking...\nGitBook Assistant\n##### Good afternoon\nI'm here to help you with the docs.\nWhat is this page about?What should I read next?Can you give an example?\n`Ctrl``i`\nAI Based on your context\nSend\n  * Getting Started\n    *     *     *     *     *     *   * Deploying ZenML\n    *     *     *   * Concepts\n    *     *     *     *     *     *     *     *     *     *     *     *     *     *     *   * Reference\n    *     *     *     *     *     * \n\nPowered by GitBook\n  * Real-world Use Case\n  * Understanding Pipeline Snapshots\n  * Creating Pipeline Snapshots\n  * Using the Python SDK\n  * Using the CLI\n  * Using the Dashboard\n  * Running Pipeline Snapshots\n  * Using the Python SDK\n  * Using the CLI\n  * Using the Dashboard\n  * Using the REST API\n  * Deleting Pipeline Snapshots\n  * Advanced Usage: Running Snapshots from Other Pipelines\n  * Method 1: Trigger by Pipeline Name (Uses Latest Snapshot)\n  * Method 2: Trigger by Specific Snapshot ID\n  * Best Practices\n\n\nWas this helpful?\nGitBook AssistantAsk\n  1. Concepts\n\n\nCreate and run pipeline snapshots.\nA **Pipeline Snapshot** is an immutable snapshot of your pipeline that includes the pipeline DAG, code, configuration, and container images. Snapshots can be run from the SDK, CLI, ZenML dashboard or via a REST API. Additionally, snapshots can also be deployed.\nSnapshots are the successor and replacement of ZenML run templates.\nRunning snapshots is a ZenML Pro-only feature.\n## \nReal-world Use Case\nImagine your team has built a robust training pipeline that needs to be run regularly with different parameters:\n  * **Data Scientists** need to experiment with new datasets and hyperparameters\n  * **MLOps Engineers** need to schedule regular retraining with production data\n  * **Stakeholders** need to trigger model training through a simple UI without coding\n\n\nWithout snapshots, each scenario would require:\n  1. Direct access to the codebase\n  2. Knowledge of pipeline implementation details\n  3. Manual pipeline configuration for each run\n\n\n**Pipeline snapshots solve this problem by creating a reusable configuration** that can be executed with different parameters from any interface:\n  * **Through Python** : Data scientists can programmatically trigger snapshots with custom parameters\n\n\nCopy```\nfrom zenml.client import Client\nClient().trigger_pipeline(\n      snapshot_name_or_id=<NAME-OR-ID>,\n      run_configuration={\n\"steps\": {\n\"data_loader\": {\"parameters\": {\"data_path\": \"s3://new-data/\"}},\n\"model_trainer\": {\"parameters\": {\"learning_rate\": 0.01}}\n          }\n      }\n  )\n```\n\n  * **Through REST API** : Your CI/CD system can trigger snapshots via API calls\n\n\nCopy```\n  curl -X POST 'https://your-zenml-server/api/v1/pipeline-snapshots/<ID>/runs' -H 'Authorization: Bearer <TOKEN>' -d '{\"steps\": {...}}'\n```\n\n  * **Through Browser** (Pro feature): Non-technical stakeholders can run snapshots directly from the ZenML dashboard by simply filling in a form with the required parameters - no coding required!\n\n\nThis enables your team to standardize execution patterns while maintaining flexibility - perfect for production ML workflows that need to be triggered from various systems.\n## \nUnderstanding Pipeline Snapshots\nWhile the simplest way to execute a ZenML pipeline is to directly call your pipeline function, pipeline snapshots offer several advantages for more complex workflows:\n  * **Standardization** : Ensure all pipeline runs follow a consistent configuration pattern\n  * **Parameterization** : Easily modify inputs and settings without changing code\n  * **Remote Execution** : Trigger pipelines through the dashboard or API without code access\n  * **Team Collaboration** : Share ready-to-use pipeline configurations with team members\n  * **Automation** : Integrate with CI/CD systems or other automated processes\n\n\n## \nCreating Pipeline Snapshots\nYou have several ways to create a snapshot in ZenML:\n### \nUsing the Python SDK\nYou can create a snapshot from your local code and configuration like this:\nCopy```\nfrom zenml import pipeline\n@pipeline\ndef my_pipeline():\n    ...\nsnapshot = my_pipeline.create_snapshot(name=\"<NAME>\")\n```\n\n### \nUsing the CLI\nYou can create a snapshot using the ZenML CLI, by passing the source path of your pipeline:\nCopy```\nzenml pipeline snapshot create <PIPELINE-SOURCE-PATH> --name=<SNAPSHOT-NAME>\n```\n\nIf you later want to run this snapshot, you need to have an active **remote stack** while running this command or you can specify one with the `--stack` option.\n### \nUsing the Dashboard\nTo create a snapshot through the ZenML dashboard:\n  1. Navigate to a pipeline run\n  2. Click on `...` in the top right, and then on `+ New Snapshot`\n  3. Enter a name for the snapshot\n  4. Click `Create`\n\n\nCreate Snapshots on the dashboard\nSnapshot Details\n## \nRunning Pipeline Snapshots\nOnce you've created a snapshot, you can run it through various interfaces:\n### \nUsing the Python SDK\nRun a snapshot programmatically:\nCopy```\nfrom zenml.client import Client\nsnapshot = Client().get_snapshot(\"<NAME-OR-ID>\", ...)\nconfig = snapshot.config_template\n# [OPTIONAL] Modify the configuration if needed\nconfig.steps[\"my_step\"].parameters[\"my_param\"] = new_value\nClient().trigger_pipeline(\n    snapshot_name_or_id=snapshot.id,\n    run_configuration=config,\n)\n```\n\n### \nUsing the CLI\nRun a snapshot using the CLI:\nCopy```\nzenml pipeline snapshot run <SNAPSHOT-NAME-OR-ID>\n# If you want to run the snapshot with a modified configuration, use the `--config=...` parameter\n```\n\n### \nUsing the Dashboard\nTo run a snapshot from the dashboard:\n  1. Either click `Run a Pipeline` on the main `Pipelines` page, or navigate to a specific snapshot and click `Run Snapshot`\n  2. On the `Run Details` page, you can:\n     * Modify the configuration using the built-in editor\n     * Upload a `.yaml` configuration file\n  3. Click `Run` to start the pipeline run\n\n\nRun Details\nOnce you run the snapshot, a new run will be executed on the same stack as the original run.\n### \nUsing the REST API\nTo run a snapshot through the REST API, you need to make a series of calls:\n  1. First, get the pipeline ID:\n\n\nCopy```\ncurl -X 'GET' \\\n  '<YOUR_ZENML_SERVER_URL>/api/v1/pipelines?hydrate=false&name=<PIPELINE-NAME>' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer <YOUR-TOKEN>'\n```\n\n  1. Using the pipeline ID, get the snapshot ID:\n\n\nCopy```\ncurl -X 'GET' \\\n  '<YOUR_ZENML_SERVER_URL>/api/v1/pipeline_snapshots?hydrate=false&logical_operator=and&page=1&size=20&pipeline_id=<PIPELINE-ID>' \\\n  -H 'accept: application/json' \\\n  -H 'Authorization: Bearer <YOUR-TOKEN>'\n```\n\n  1. Finally, trigger the snapshot:\n\n\nCopy```\ncurl -X 'POST' \\\n  '<YOUR_ZENML_SERVER_URL>/api/v1/pipeline_snapshots/<SNAPSHOT-ID>/runs' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer <YOUR-TOKEN>' \\\n  -d '{\n  \"steps\": {\"model_trainer\": {\"parameters\": {\"model_type\": \"rf\"}}}\n}'\n```\n\nLearn how to get a bearer token for the curl commands:\n  * For a ZenML OSS API: use service accounts + API keys.\n  * For a ZenML Pro workspace API: use ZenML Pro Personal Access Tokens or ZenML Pro Organization Service Accounts.\n\n\n## \nDeleting Pipeline Snapshots\nYou can delete a snapshot using the CLI:\nCopy```\nzenml pipeline snapshot delete <SNAPSHOT-NAME-OR-ID>\n```\n\nYou can also delete a snapshot using the Python SDK:\nCopy```\nfrom zenml.client import Client\nClient().delete_snapshot(name_id_or_prefix=<SNAPSHOT-NAME-OR-ID>)\n```\n\n## \nAdvanced Usage: Running Snapshots from Other Pipelines\nYou can run snapshots from within other pipelines, enabling complex workflows. There are two ways to do this:\n### \nMethod 1: Trigger by Pipeline Name (Uses Latest Snapshot)\nIf you want to run the latest runnable snapshot for a specific pipeline:\nCopy```\nimport pandas as pd\nfrom zenml import pipeline, step\nfrom zenml.artifacts.unmaterialized_artifact import UnmaterializedArtifact\nfrom zenml.artifacts.utils import load_artifact\nfrom zenml.client import Client\nfrom zenml.config.pipeline_run_configuration import PipelineRunConfiguration\n@step\ndef trainer(data_artifact_id: str):\n    df = load_artifact(data_artifact_id)\n@pipeline\ndef training_pipeline():\n    trainer()\n@step\ndef load_data() -> pd.DataFrame:\n    # Your data loading logic here\n    return pd.DataFrame()\n@step\ndef trigger_pipeline(df: UnmaterializedArtifact):\n    # By using UnmaterializedArtifact we can get the ID of the artifact\n    run_config = PipelineRunConfiguration(\n        steps={\"trainer\": {\"parameters\": {\"data_artifact_id\": df.id}}}\n    )\n    # This triggers the LATEST runnable snapshot for the \"training_pipeline\" pipeline\n    Client().trigger_pipeline(pipeline_name_or_id=\"training_pipeline\", run_configuration=run_config)\n@pipeline\ndef loads_data_and_triggers_training():\n    df = load_data()\n    trigger_pipeline(df)  # Will trigger the other pipeline\n```\n\n### \nMethod 2: Trigger by Specific Snapshot ID\nIf you want to run a specific snapshot (not necessarily the latest one):\nCopy```\n@step\ndef trigger_specific_snapshot(df: UnmaterializedArtifact):\n    run_config = PipelineRunConfiguration(\n        steps={\"trainer\": {\"parameters\": {\"data_artifact_id\": df.id}}}\n    )\n    \n    Client().trigger_pipeline(snapshot_name_or_id=<SNAPSHOT-NAME-OR-ID>, run_configuration=run_config)\n```\n\n**Key Difference** :\n  * `Client().trigger_pipeline(\"pipeline_name\", ...)` uses the pipeline name and runs the **latest** snapshot for that pipeline\n  * `Client().trigger_pipeline(snapshot_id=<ID>, ...)` runs a **specific** snapshot by its unique ID\n\n\nThe newly created pipeline run will show up in the DAG next to the step that triggered it:\nPipeline Snapshot triggered by Step\nThis pattern is useful for:\n  * Creating pipeline dependencies\n  * Implementing dynamic workflow orchestration\n  * Building multi-stage ML pipelines where different steps require different resources\n  * Separating data preparation from model training\n\n\nRead more about:\n  * PipelineRunConfiguration\n  * trigger_pipeline API\n  * Unmaterialized Artifacts\n\n\n## \nBest Practices\n  1. **Use descriptive names** for your snapshots to make them easily identifiable\n  2. **Document snapshot parameters** so other team members understand how to configure them\n  3. **Start with a working pipeline run** before creating a snapshot to ensure it's properly configured\n  4. **Test snapshots with different configurations** to verify they work as expected\n  5. **Use version control** for your snapshot configurations when storing them as YAML files\n  6. **Implement access controls** to manage who can run specific snapshots\n  7. **Monitor snapshot usage** to understand how your team is using them\n\n\n**Important:** You need to recreate your snapshots after upgrading your ZenML server. Snapshots are tied to specific server versions and may not work correctly after an upgrade.\nPreviousService ConnectorsNextPipeline Deployments\nLast updated 22 days ago\nWas this helpful?\n",
    "summary": null,
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts",
        "https://zenml.io/pro",
        "https://docs.zenml.io/concepts/steps_and_pipelines/sources",
        "https://docs.zenml.io/how-to/manage-zenml-server/connecting-to-zenml/connect-with-a-service-account",
        "https://docs.zenml.io/pro/access-management/personal-access-tokens",
        "https://docs.zenml.io/pro/access-management/service-accounts",
        "https://sdkdocs.zenml.io/latest/core_code_docs/core-config.html",
        "https://sdkdocs.zenml.io/latest/core_code_docs/core-client.html",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/"
    ]
}