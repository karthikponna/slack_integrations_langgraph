{
    "id": "bfa4a07ec727a423b3fa9ae942d4dba2",
    "metadata": {
        "id": "bfa4a07ec727a423b3fa9ae942d4dba2",
        "url": "https://docs.zenml.io/concepts/artifacts/materializers",
        "title": "Materializers | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Understanding and creating materializers to handle custom data types in ZenML pipelines",
            "keywords": null,
            "author": null,
            "og:title": "Materializers | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Understanding and creating materializers to handle custom data types in ZenML pipelines",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/dt8cXDYl92xHenfmpTar",
            "twitter:card": "summary_large_image",
            "twitter:title": "Materializers | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Understanding and creating materializers to handle custom data types in ZenML pipelines",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/dt8cXDYl92xHenfmpTar"
        }
    },
    "content": "`⌘``k`\nGitBook Assistant\nProductResourcesGitHubStart free\nMore\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\nGitBook Assistant\nGitBook Assistant\nWorking...Thinking...\nGitBook Assistant\n##### Good afternoon\nI'm here to help you with the docs.\nWhat is this page about?What should I read next?Can you give an example?\n`⌘``i`\nAI Based on your context\nSend\n  * Getting Started\n    *     *     *     *     *     *   * Deploying ZenML\n    *     *     *   * Concepts\n    *     *       * Materializers\n      * Visualizations\n    *     *     *     *     *     *     *     *     *     *     *     *     *   * Reference\n    *     *     *     *     *     * \n\nPowered by GitBook\n  * What Are Materializers?\n  * Built-In Materializers\n  * Core Materializers\n  * Integration-Specific Materializers\n  * Creating Custom Materializers\n  * 1. Define Your Materializer Class\n  * 2. Using Your Custom Materializer\n  * 3. Multiple Outputs with Different Materializers\n  * 4. Registering a Materializer Globally\n  * Materializer Implementation Details\n  * Handling Storage\n  * Visualization Support\n  * Metadata Extraction\n  * Temporary Files\n  * Example: A Complete Materializer\n  * Unmaterialized artifacts\n  * Best Practices\n  * Conclusion\n\n\nWas this helpful?\nGitBook AssistantAsk\n  1. Concepts\n  2. \n\n# Materializers\nUnderstanding and creating materializers to handle custom data types in ZenML pipelines\nMaterializers are a core concept in ZenML that enable the serialization, storage, and retrieval of artifacts in your ML pipelines. This guide explains how materializers work and how to create custom materializers for your specific data types.\n## \nWhat Are Materializers?\nA materializer is a class that defines how a particular data type is:\n  * **Serialized** : Converted from Python objects to a storable format\n  * **Saved** : Written to the artifact store\n  * **Loaded** : Read from the artifact store\n  * **Deserialized** : Converted back to Python objects\n  * **Visualized** : Displayed in the ZenML dashboard\n  * **Analyzed** : Metadata extraction for tracking and search\n\n\nMaterializers act as the bridge between your Python code and the underlying storage system, ensuring that any artifact can be saved, loaded, and visualized correctly, regardless of the data type.\n## \nBuilt-In Materializers\nZenML includes built-in materializers for many common data types:\n### \nCore Materializers\nMaterializer\nHandled Data Types\nStorage Format\nBuiltInMaterializer\n`bool`, `float`, `int`, `str`, `None`\n`.json`\nBytesInMaterializer\n`bytes`\n`.txt`\nBuiltInContainerMaterializer\n`dict`, `list`, `set`, `tuple`\nDirectory\nNumpyMaterializer\n`np.ndarray`\n`.npy`\nPandasMaterializer\n`pd.DataFrame`, `pd.Series`\n`.csv` (or `.gzip` if `parquet` is installed)\nPydanticMaterializer\n`pydantic.BaseModel`\n`.json`\nServiceMaterializer\n`zenml.services.service.BaseService`\n`.json`\nStructuredStringMaterializer\n`zenml.types.CSVString`, `zenml.types.HTMLString`, `zenml.types.MarkdownString`\n`.csv` / `.html` / `.md` (depending on type)\nZenML also provides a CloudpickleMaterializer that can handle any object by saving it with cloudpickle. However, this is not production-ready because the resulting artifacts cannot be loaded when running with a different Python version. For production use, you should implement a custom materializer for your specific data types.\n### \nIntegration-Specific Materializers\nWhen you install ZenML integrations, additional materializers become available:\nIntegration\nMaterializer\nHandled Data Types\nStorage Format\nbentoml\nBentoMaterializer\n`bentoml.Bento`\n`.bento`\ndeepchecks\nDeepchecksResultMateriailzer\n`deepchecks.CheckResult`, `deepchecks.SuiteResult`\n`.json`\nevidently\nEvidentlyProfileMaterializer\n`evidently.Profile`\n`.json`\ngreat_expectations\nGreatExpectationsMaterializer\n`great_expectations.ExpectationSuite`, `great_expectations.CheckpointResult`\n`.json`\nhuggingface\nHFDatasetMaterializer\n`datasets.Dataset`, `datasets.DatasetDict`\nDirectory\nhuggingface\nHFPTModelMaterializer\n`transformers.PreTrainedModel`\nDirectory\nhuggingface\nHFTFModelMaterializer\n`transformers.TFPreTrainedModel`\nDirectory\nhuggingface\nHFTokenizerMaterializer\n`transformers.PreTrainedTokenizerBase`\nDirectory\nlightgbm\nLightGBMBoosterMaterializer\n`lgbm.Booster`\n`.txt`\nlightgbm\nLightGBMDatasetMaterializer\n`lgbm.Dataset`\n`.binary`\nneural_prophet\nNeuralProphetMaterializer\n`NeuralProphet`\n`.pt`\npillow\nPillowImageMaterializer\n`Pillow.Image`\n`.PNG`\npolars\nPolarsMaterializer\n`pl.DataFrame`, `pl.Series`\n`.parquet`\npycaret\nPyCaretMaterializer\nAny `sklearn`, `xgboost`, `lightgbm` or `catboost` model\n`.pkl`\npytorch\nPyTorchDataLoaderMaterializer\n`torch.Dataset`, `torch.DataLoader`\n`.pt`\npytorch\nPyTorchModuleMaterializer\n`torch.Module`\n`.pt`\nscipy\nSparseMaterializer\n`scipy.spmatrix`\n`.npz`\nspark\nSparkDataFrameMaterializer\n`pyspark.DataFrame`\n`.parquet`\nspark\nSparkModelMaterializer\n`pyspark.Transformer`\n`pyspark.Estimator`\ntensorflow\nKerasMaterializer\n`tf.keras.Model`\nDirectory\ntensorflow\nTensorflowDatasetMaterializer\n`tf.Dataset`\nDirectory\nwhylogs\nWhylogsMaterializer\n`whylogs.DatasetProfileView`\n`.pb`\nxgboost\nXgboostBoosterMaterializer\n`xgb.Booster`\n`.json`\nxgboost\nXgboostDMatrixMaterializer\n`xgb.DMatrix`\n`.binary`\njax\nJAXArrayMaterializer\n`jax.Array`\n`.npy`\nmlx\nMLXArrayMaterializer\n`mlx.core.array`\n`.npy`\n> **Note** : When using Docker-based orchestrators, you must specify the appropriate integrations in your `DockerSettings` to ensure the materializers are available inside the container.\n## \nCreating Custom Materializers\nWhen working with custom data types, you'll need to create materializers to handle them. Here's how:\n### \n1. Define Your Materializer Class\nCreate a new class that inherits from `BaseMaterializer`:\nCopy```\nimport os\nimport json\nfrom typing import Type, Any, Dict\nfrom zenml.materializers.base_materializer import BaseMaterializer\nfrom zenml.enums import ArtifactType, VisualizationType\nfrom zenml.metadata.metadata_types import MetadataType\n# Assume MyClass is your custom class defined elsewhere\n# from mymodule import MyClass\nclass MyClassMaterializer(BaseMaterializer):\n    \"\"\"Materializer for MyClass objects.\"\"\"\n    \n    # List the data types this materializer can handle\n    ASSOCIATED_TYPES = (MyClass,)\n    \n    # Define what type of artifact this is (usually DATA or MODEL)\n    ASSOCIATED_ARTIFACT_TYPE = ArtifactType.DATA\n    \n    def load(self, data_type: Type[Any]) -> MyClass:\n        \"\"\"Load MyClass from storage.\"\"\"\n        # Implementation here\n        filepath = os.path.join(self.uri, \"data.json\")\n        with self.artifact_store.open(filepath, \"r\") as f:\n            data = json.load(f)\n        \n        # Create and return an instance of MyClass\n        return MyClass(**data)\n    \n    def save(self, data: MyClass) -> None:\n        \"\"\"Save MyClass to storage.\"\"\"\n        # Implementation here\n        filepath = os.path.join(self.uri, \"data.json\")\n        with self.artifact_store.open(filepath, \"w\") as f:\n            json.dump(data.to_dict(), f)\n    \n    def save_visualizations(self, data: MyClass) -> Dict[str, VisualizationType]:\n        \"\"\"Generate visualizations for the dashboard.\"\"\"\n        # Optional - generate visualizations\n        vis_path = os.path.join(self.uri, \"visualization.html\")\n        with self.artifact_store.open(vis_path, \"w\") as f:\n            f.write(data.to_html())\n        \n        return {vis_path: VisualizationType.HTML}\n    \n    def extract_metadata(self, data: MyClass) -> Dict[str, MetadataType]:\n        \"\"\"Extract metadata for tracking.\"\"\"\n        # Optional - extract metadata\n        return {\n            \"name\": data.name,\n            \"created_at\": data.created_at,\n            \"num_records\": len(data.records)\n        }\n```\n\n### \n2. Using Your Custom Materializer\nOnce you've defined the materializer, you can use it in your pipeline:\nCopy```\nfrom zenml import step, pipeline\n# from mymodule import MyClass, MyClassMaterializer\n@step(output_materializers=MyClassMaterializer)\ndef create_my_class() -> MyClass:\n    \"\"\"Create an instance of MyClass.\"\"\"\n    return MyClass(name=\"test\", records=[1, 2, 3])\n@step\ndef use_my_class(my_obj: MyClass) -> None:\n    \"\"\"Use the MyClass instance.\"\"\"\n    print(f\"Name: {my_obj.name}, Records: {my_obj.records}\")\n@pipeline\ndef custom_pipeline():\n    data = create_my_class()\n    use_my_class(data)\n```\n\n### \n3. Multiple Outputs with Different Materializers\nWhen a step has multiple outputs that need different materializers:\nCopy```\nfrom typing import Tuple, Annotated\n@step(output_materializers={\n    \"obj1\": MyClass1Materializer,\n    \"obj2\": MyClass2Materializer\n})\ndef create_objects() -> Tuple[\n    Annotated[MyClass1, \"obj1\"],\n    Annotated[MyClass2, \"obj2\"]\n]:\n    \"\"\"Create instances of different classes.\"\"\"\n    return MyClass1(), MyClass2()\n```\n\n### \n4. Registering a Materializer Globally\nYou can register a materializer globally to override the default materializer for a specific type:\nCopy```\nfrom zenml.materializers.materializer_registry import materializer_registry\nfrom zenml.materializers.base_materializer import BaseMaterializer\nimport pandas as pd\n# Create a custom pandas materializer\nclass FastPandasMaterializer(BaseMaterializer):\n    # Implementation here\n    ...\n# Register it for pandas DataFrames globally\nmaterializer_registry.register_and_overwrite_type(\n    key=pd.DataFrame, \n    type_=FastPandasMaterializer\n)\n```\n\n## \nMaterializer Implementation Details\nWhen implementing a custom materializer, consider these aspects:\n### \nHandling Storage\nThe `self.uri` property contains the path to the directory where your artifact should be stored. Use this path to create files or subdirectories for your data.\nWhen reading or writing files, always use `self.artifact_store.open()` rather than direct file I/O to ensure compatibility with different artifact stores (local filesystem, cloud storage, etc.).\n### \nVisualization Support\nThe `save_visualizations()` method allows you to create visualizations that will be shown in the ZenML dashboard. You can return multiple visualizations of different types:\n  * `VisualizationType.HTML`: Embedded HTML content\n  * `VisualizationType.MARKDOWN`: Markdown content\n  * `VisualizationType.IMAGE`: Image files\n  * `VisualizationType.CSV`: CSV tables\n\n\n**Configuring Visualizations**\nSome materializers support configuration via environment variables to customize their visualization behavior. For example:\n  * `ZENML_PANDAS_SAMPLE_ROWS`: Controls the number of rows shown in sample visualizations created by the `PandasMaterializer`. Default is 10 rows.\n\n\n### \nMetadata Extraction\nThe `extract_metadata()` method allows you to extract key information about your artifact for indexing and searching. This metadata will be displayed alongside the artifact in the dashboard.\n### \nTemporary Files\nIf you need a temporary directory while processing artifacts, use the `get_temporary_directory()` helper:\nCopy```\nwith self.get_temporary_directory() as temp_dir:\n    # Process files in the temporary directory\n    # Files will be automatically cleaned up\n```\n\n### \nExample: A Complete Materializer\nHere's a complete example of a custom materializer for a simple class:\nCopy```\nimport os\nimport json\nfrom typing import Type, Any, Dict\nfrom zenml.materializers.base_materializer import BaseMaterializer\nfrom zenml.enums import ArtifactType\nclass MyObj:\n    def __init__(self, name: str):\n        self.name = name\n    \n    def to_dict(self):\n        return {\"name\": self.name}\n    \n    @classmethod\n    def from_dict(cls, data):\n        return cls(name=data[\"name\"])\nclass MyMaterializer(BaseMaterializer):\n    \"\"\"Materializer for MyObj objects.\"\"\"\n    \n    ASSOCIATED_TYPES = (MyObj,)\n    ASSOCIATED_ARTIFACT_TYPE = ArtifactType.DATA\n    \n    def load(self, data_type: Type[Any]) -> MyObj:\n        \"\"\"Load MyObj from storage.\"\"\"\n        filepath = os.path.join(self.uri, \"data.json\")\n        with self.artifact_store.open(filepath, \"r\") as f:\n            data = json.load(f)\n        \n        return MyObj.from_dict(data)\n    \n    def save(self, data: MyObj) -> None:\n        \"\"\"Save MyObj to storage.\"\"\"\n        filepath = os.path.join(self.uri, \"data.json\")\n        with self.artifact_store.open(filepath, \"w\") as f:\n            json.dump(data.to_dict(), f)\n# Usage in a pipeline\n@step(output_materializers=MyMaterializer)\ndef create_my_obj() -> MyObj:\n    return MyObj(name=\"my_object\")\n@step\ndef use_my_obj(my_obj: MyObj) -> None:\n    print(f\"Object name: {my_obj.name}\")\n@pipeline\ndef my_pipeline():\n    obj = create_my_obj()\n    use_my_obj(obj)\n```\n\n## \nUnmaterialized artifacts\nWhenever you pass artifacts as outputs from one pipeline step to other steps as inputs, the corresponding materializer for the respective data type defines how this artifact is first serialized and written to the artifact store, and then deserialized and read in the next step.handle-custom-data-types. However, there are instances where you might **not** want to materialize an artifact in a step, but rather use a reference to it instead. This is where skipping materialization comes in.\nSkipping materialization might have unintended consequences for downstream tasks that rely on materialized artifacts. Only skip materialization if there is no other way to do what you want to do.\n#### \nHow to skip materialization\nWhile materializers should in most cases be used to control how artifacts are returned and consumed from pipeline steps, you might sometimes need to have a completely unmaterialized artifact in a step, e.g., if you need to know the exact path to where your artifact is stored.\nAn unmaterialized artifact is a `zenml.materializers.UnmaterializedArtifact`. Among others, it has a property `uri` that points to the unique path in the artifact store where the artifact is persisted. One can use an unmaterialized artifact by specifying `UnmaterializedArtifact` as the type in the step:\nCopy```\nfrom zenml.artifacts.unmaterialized_artifact import UnmaterializedArtifact\nfrom zenml import step\n@step\ndef my_step(my_artifact: UnmaterializedArtifact):  # rather than pd.DataFrame\n    pass\n```\n\nThe following shows an example of how unmaterialized artifacts can be used in the steps of a pipeline. The pipeline we define will look like this:\nCopy```\ns1 -> s3 \ns2 -> s4\n```\n\n`s1` and `s2` produce identical artifacts, however `s3` consumes materialized artifacts while `s4` consumes unmaterialized artifacts. `s4` can now use the `dict_.uri` and `list_.uri` paths directly rather than their materialized counterparts.\nCopy```\nfrom typing import Annotated\nfrom typing import Dict, List, Tuple\nfrom zenml.artifacts.unmaterialized_artifact import UnmaterializedArtifact\nfrom zenml import pipeline, step\n@step\ndef step_1() -> Tuple[\n    Annotated[Dict[str, str], \"dict_\"],\n    Annotated[List[str], \"list_\"],\n]:\n    return {\"some\": \"data\"}, []\n@step\ndef step_2() -> Tuple[\n    Annotated[Dict[str, str], \"dict_\"],\n    Annotated[List[str], \"list_\"],\n]:\n    return {\"some\": \"data\"}, []\n@step\ndef step_3(dict_: Dict, list_: List) -> None:\n    assert isinstance(dict_, dict)\n    assert isinstance(list_, list)\n@step\ndef step_4(\n        dict_: UnmaterializedArtifact,\n        list_: UnmaterializedArtifact,\n) -> None:\n    print(dict_.uri)\n    print(list_.uri)\n@pipeline\ndef example_pipeline():\n    step_3(*step_1())\n    step_4(*step_2())\nexample_pipeline()\n```\n\nYou can see another example of using an `UnmaterializedArtifact` when triggering a pipeline from another.\n## \nBest Practices\nWhen working with materializers:\n  1. **Prefer structured formats** over pickle or other binary formats for better cross-environment compatibility.\n  2. **Test your materializer** with different artifact stores (local, S3, etc.) to ensure it works consistently.\n  3. **Consider versioning** if your data structure might change over time.\n  4. **Create visualizations** to help users understand your artifacts in the dashboard.\n  5. **Extract useful metadata** to make artifacts easier to find and understand.\n  6. **Be explicit** about materializer assignments for clarity, even if ZenML can detect them automatically.\n  7. **Avoid using the CloudpickleMaterializer** in production as it's not reliable across different Python versions.\n\n\n## \nConclusion\nMaterializers are a powerful part of ZenML's artifact system, enabling proper storage and handling of any data type. By creating custom materializers for your specific data structures, you ensure that your ML pipelines are robust, efficient, and can handle any data type required by your workflows.\nPreviousArtifactsNextVisualizations\nLast updated 1 month ago\nWas this helpful?\nThis site uses cookies to deliver its service and to analyze traffic. By browsing this site, you accept the privacy policy.\nAcceptReject\n",
    "summary": null,
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/artifacts/materializers",
        "https://docs.zenml.io/concepts/artifacts/visualizations",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts",
        "https://sdkdocs.zenml.io/latest/core_code_docs/core-materializers.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-bentoml.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-deepchecks.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-evidently.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-great_expectations.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-huggingface.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-lightgbm.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-neural_prophet.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-pillow.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-polars.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-pycaret.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-pytorch.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-scipy.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-spark.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-tensorflow.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-whylogs.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-xgboost.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-jax.html",
        "https://sdkdocs.zenml.io/latest/integration_code_docs/integrations-mlx.html",
        "https://sdkdocs.zenml.io/latest/core_code_docs/core-artifacts.html",
        "https://www.zenml.io/privacy-policy",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/",
        "https://github.com/cloudpipe/cloudpickle"
    ]
}